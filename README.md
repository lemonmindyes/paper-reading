# paper-reading

![visitors](https://visitor-badge.laobi.icu/badge?page_id=lemonmindyes/paper-reading)

记录整理阅读的paper。star表示个人对该论文的重要性程度排行，最不重要1星，最重要5星。如果论文太难懂会酌情降星。

- 日期：论文发表日期
- 标题：论文题目
- 领域：使用ChatGPT生成。prompt：这个论文的题目[title]，这个论文的地址[arxiv的pdf的url]，请你分析一下这个论文属于[大主题]的什么领域
- star：根据论文重要性，阅读难度。本人的主观评价
- 引用：使用semanticscholar的api获取
- link：论文的arxiv地址

---

## NLP-自然语言处理

|    日期    |                             标题                             |             领域              | star  |                             引用                             |                             link                             |
| :--------: | :----------------------------------------------------------: | :---------------------------: | :---: | :----------------------------------------------------------: | :----------------------------------------------------------: |
| 6/11/2019  | Fast Transformer Decoding: One Write-Head is All You Need（MQA） | **Transformer多头注意力机制** |  ⭐⭐⭐  | [![citation](https://img.shields.io/badge/dynamic/json?label=citation&query=citationCount&url=https%3A%2F%2Fapi.semanticscholar.org%2Fgraph%2Fv1%2Fpaper%2Fdc52b09089704ebd6f471177474bc29741c50023%3Ffields%3DcitationCount)](https://www.semanticscholar.org/paper/ImageNet-classification-with-deep-convolutional-Krizhevsky-Sutskever/dc52b09089704ebd6f471177474bc29741c50023) |           [link](https://arxiv.org/abs/1911.02150)           |
| 10/1/2023  | Chain-of-Thought Prompting Elicits Reasoning in Large Language Models |        **提示工程COT**        | ⭐⭐⭐⭐⭐ | [![citation](https://img.shields.io/badge/dynamic/json?label=citation&query=citationCount&url=https%3A%2F%2Fapi.semanticscholar.org%2Fgraph%2Fv1%2Fpaper%2F1b6e810ce0afd0dd093f789d2b2742d047e316d5%3Ffields%3DcitationCount)](https://www.semanticscholar.org/paper/ImageNet-classification-with-deep-convolutional-Krizhevsky-Sutskever/1b6e810ce0afd0dd093f789d2b2742d047e316d5) |           [link](https://arxiv.org/abs/2201.11903)           |
|  8/1/2025  | Towards System 2 Reasoning in LLMs: Learning How to Think With Meta Chain-of-Thought |        **提示工程COT**        |  ⭐⭐   | [![citation](https://img.shields.io/badge/dynamic/json?label=citation&query=citationCount&url=https%3A%2F%2Fapi.semanticscholar.org%2Fgraph%2Fv1%2Fpaper%2F0e63a3aebf14fc7a68c0df7a922770bde5b77360%3Ffields%3DcitationCount)](https://www.semanticscholar.org/paper/ImageNet-classification-with-deep-convolutional-Krizhevsky-Sutskever/0e63a3aebf14fc7a68c0df7a922770bde5b77360) |           [link](https://arxiv.org/abs/2501.04682)           |
| 19/8/2025  | Efficient Attention Methods: Hardware-efficient,<br/>Sparse, Compact, and Linear Attention |    **有效注意力计算综述**     | ⭐⭐⭐⭐⭐ |                                                              | [link](https://github.com/attention-survey/Efficient_Attention_Survey?tab=readme-ov-file) |
| 29/9/2025  | Understanding the Dilemma of Unlearning for Large Language Models |    **机器遗忘与可解释性**     |  ⭐⭐   | [![citation](https://img.shields.io/badge/dynamic/json?label=citation&query=citationCount&url=https%3A%2F%2Fapi.semanticscholar.org%2Fgraph%2Fv1%2Fpaper%2F0a0e608a20f2cebce8911368573280a2b897b1b0%3Ffields%3DcitationCount)](https://www.semanticscholar.org/paper/ImageNet-classification-with-deep-convolutional-Krizhevsky-Sutskever/0a0e608a20f2cebce8911368573280a2b897b1b0) |           [link](https://arxiv.org/abs/2509.24675)           |
| 29/9/2025  | InfLLM-V2: Dense-Sparse Switchable Attention for Seamless Short-to-Long Adaptation |   **Transformer稀疏注意力**   | ⭐⭐⭐⭐  | [![citation](https://img.shields.io/badge/dynamic/json?label=citation&query=citationCount&url=https%3A%2F%2Fapi.semanticscholar.org%2Fgraph%2Fv1%2Fpaper%2Fccef1988a262e9e6622607d394d83d82670d4e1f%3Ffields%3DcitationCount)](https://www.semanticscholar.org/paper/ImageNet-classification-with-deep-convolutional-Krizhevsky-Sutskever/ccef1988a262e9e6622607d394d83d82670d4e1f) |           [link](https://arxiv.org/abs/2509.24663)           |
| 8/10/2025  | KnowRL: Exploring Knowledgeable Reinforcement Learning for Factuality |    **大模型训练降低幻觉**     | ⭐⭐⭐⭐  | [![citation](https://img.shields.io/badge/dynamic/json?label=citation&query=citationCount&url=https%3A%2F%2Fapi.semanticscholar.org%2Fgraph%2Fv1%2Fpaper%2F344b7374b1b78df4a4d488e38cd94af7d84ec6c0%3Ffields%3DcitationCount)](https://www.semanticscholar.org/paper/ImageNet-classification-with-deep-convolutional-Krizhevsky-Sutskever/344b7374b1b78df4a4d488e38cd94af7d84ec6c0) |           [link](https://arxiv.org/abs/2506.19807)           |
| 12/10/2025 | Towards Thinking-Optimal Scaling of Test-Time Compute for LLM Reasoning |  **LLM 推理能力与推理策略**   |  ⭐⭐⭐  | [![citation](https://img.shields.io/badge/dynamic/json?label=citation&query=citationCount&url=https%3A%2F%2Fapi.semanticscholar.org%2Fgraph%2Fv1%2Fpaper%2F73f60e2190180fbffd678b63993b56e95a2cf994%3Ffields%3DcitationCount)](https://www.semanticscholar.org/paper/ImageNet-classification-with-deep-convolutional-Krizhevsky-Sutskever/73f60e2190180fbffd678b63993b56e95a2cf994) |           [link](https://arxiv.org/abs/2502.18080)           |
| 20/10/2025 |                     The Free Transformer                     |   **Transformer 架构创新**    |   ⭐   | [![citation](https://img.shields.io/badge/dynamic/json?label=citation&query=citationCount&url=https%3A%2F%2Fapi.semanticscholar.org%2Fgraph%2Fv1%2Fpaper%2Fc672c73860c395ed3fcf679d55dcb8b7c2c9c83a%3Ffields%3DcitationCount)](https://www.semanticscholar.org/paper/ImageNet-classification-with-deep-convolutional-Krizhevsky-Sutskever/c672c73860c395ed3fcf679d55dcb8b7c2c9c83a) |           [link](https://arxiv.org/abs/2510.17558)           |
| 25/10/2025 | Mixture-of-Recursions: Learning Dynamic Recursive Depths for Adaptive Token-Level Computation |   **Transformer 架构创新**    |  ⭐⭐⭐  | [![citation](https://img.shields.io/badge/dynamic/json?label=citation&query=citationCount&url=https%3A%2F%2Fapi.semanticscholar.org%2Fgraph%2Fv1%2Fpaper%2F875418bb21265276be9298b50e52a6c53ff3a202%3Ffields%3DcitationCount)](https://www.semanticscholar.org/paper/ImageNet-classification-with-deep-convolutional-Krizhevsky-Sutskever/875418bb21265276be9298b50e52a6c53ff3a202) |           [link](https://arxiv.org/abs/2507.10524)           |
| 21/11/2025 |       Asking LLMs to Verify First is Almost Free Lunch       |  **LLM 推理能力与推理策略**   |  ⭐⭐   | [![citation](https://img.shields.io/badge/dynamic/json?label=citation&query=citationCount&url=https%3A%2F%2Fapi.semanticscholar.org%2Fgraph%2Fv1%2Fpaper%2Fa753177e96ba231a46c8f23034234d1b40b6c176%3Ffields%3DcitationCount)](https://www.semanticscholar.org/paper/ImageNet-classification-with-deep-convolutional-Krizhevsky-Sutskever/a753177e96ba231a46c8f23034234d1b40b6c176) |           [link](https://arxiv.org/abs/2511.21734)           |

